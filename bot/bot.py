import os
import re
import json
import hashlib
import pytz
import telebot
import requests
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from dotenv import load_dotenv

load_dotenv()

# === –¢–û–ö–ï–ù–´ ===
TOKEN = os.getenv("TELEGRAM_TOKEN")
VK_TOKEN = os.getenv("VK_TOKEN")
VK_GROUP_ID = os.getenv("VK_GROUP_ID")

CHANNEL_ID = "@newsSVOih"
SEEN_IDS_FILE = "seen_ids.txt"
bot = telebot.TeleBot(TOKEN)
moscow = pytz.timezone("Europe/Moscow")

# ==============================
# 1. –û–ß–ò–°–¢–ö–ê –¢–ï–ö–°–¢–ê
# ==============================
def clean_text(text):
    if not text:
        return ""
    unwanted = [
        r"üí™\s*–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Å–≤–æ–∏—Ö\s*üá∑üá∫",
        r"–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Å–≤–æ–∏—Ö",
        r"https://t\.me/newsSVOih",
        r"@[\w\d_]+"
    ]
    for p in unwanted:
        text = re.sub(p, "", text, flags=re.IGNORECASE)
    text = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000026FF\U00002700-\U000027BF\U0001F900-\U0001F9FF]+', '', text)
    return re.sub(r'\s+', ' ', text).strip()

# ==============================
# 2. –†–ï–ü–û–°–¢ –í –í–ö (—Ñ–æ—Ç–æ + –≤–∏–¥–µ–æ)
# ==============================
def post_to_vk(caption: str, text: str, file_url: str = None, content_type: str = None, tg_link: str = None):
    if not VK_TOKEN or not VK_GROUP_ID:
        print("VK —Ç–æ–∫–µ–Ω/–≥—Ä—É–ø–ø–∞ –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –í–ö")
        return

    full_text = f"{caption}\n\n{text}".strip()
    if tg_link:
        full_text += f"\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {tg_link}"
    else:
        full_text += "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: –ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è –°–≤–æ–∏—Ö"

    attachments = []
    temp_file = None

    try:
        # --- –§–æ—Ç–æ ---
        if file_url and content_type == "photo":
            temp_file = "temp_vk.jpg"
            with open(temp_file, "wb") as f:
                f.write(requests.get(file_url).content)
            upload_url = requests.get(
                "https://api.vk.com/method/photos.getWallUploadServer",
                params={"group_id": VK_GROUP_ID, "access_token": VK_TOKEN, "v": "5.199"}
            ).json()["response"]["upload_url"]
            uploaded = requests.post(upload_url, files={"photo": open(temp_file, "rb")}).json()
            photo = requests.post(
                "https://api.vk.com/method/photos.saveWallPhoto",
                data={
                    "group_id": VK_GROUP_ID,
                    "photo": uploaded["photo"],
                    "server": uploaded["server"],
                    "hash": uploaded["hash"],
                    "access_token": VK_TOKEN,
                    "v": "5.199"
                }
            ).json()["response"][0]
            attachments.append(f"photo{photo['owner_id']}_{photo['id']}")

        # --- –í–∏–¥–µ–æ ---
        elif file_url and content_type == "video":
            size = len(requests.get(file_url, stream=True).content)
            if size > 50_000_000:  # VK –ª–∏–º–∏—Ç ~50MB
                print(f"–í–∏–¥–µ–æ {size/1e6:.1f}MB ‚Äî —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ, –ø–æ—Å—Ç–∏–º –±–µ–∑ –≤–∏–¥–µ–æ")
            else:
                temp_file = "temp_vk.mp4"
                with open(temp_file, "wb") as f:
                    f.write(requests.get(file_url).content)
                video = requests.post(
                    "https://api.vk.com/method/video.save",
                    data={
                        "group_id": VK_GROUP_ID,
                        "name": caption[:50] or "–í–∏–¥–µ–æ",
                        "access_token": VK_TOKEN,
                        "v": "5.199"
                    }
                ).json()["response"]
                requests.post(video["upload_url"], files={"video_file": open(temp_file, "rb")})
                attachments.append(f"video{video['owner_id']}_{video['video_id']}")

        # --- –ü—É–±–ª–∏–∫–∞—Ü–∏—è ---
        requests.post(
            "https://api.vk.com/method/wall.post",
            data={
                "owner_id": f"-{VK_GROUP_ID}",
                "from_group": 1,
                "message": full_text[:4095],
                "attachments": ",".join(attachments),
                "access_token": VK_TOKEN,
                "v": "5.199"
            }
        )
        print("–£—Å–ø–µ—à–Ω–æ –∑–∞–ø–æ—â–µ–Ω–æ –≤ –í–ö ‚úÖ")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –í–ö: {e}")
    finally:
        for f in ["temp_vk.jpg", "temp_vk.mp4"]:
            if temp_file == f and os.path.exists(f):
                os.remove(f)

# ==============================
# 3. –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ö–ê–†–¢–û–ß–ö–ò
# ==============================
def format_post(message, caption_override=None, group_size=1, is_urgent=False):
    timestamp = message.date
    formatted_time = datetime.fromtimestamp(timestamp, moscow).strftime("%d.%m.%Y %H:%M")
    iso_time = datetime.fromtimestamp(timestamp, moscow).strftime("%Y-%m-%dT%H:%M:%S+03:00")
    caption = clean_text(caption_override or message.caption or "")
    text = clean_text(message.text or "")
    full_text = re.sub(r'#—Å—Ä–æ—á–Ω–æ', '', f"{caption} {text}", flags=re.IGNORECASE).strip()
    if caption and text:
        caption = full_text.split(text)[0].strip()
    else:
        caption = full_text
        text = ""

    file_url = None
    thumb_url = "https://newsforsvoi.ru/preview.jpg"
    html = ""

    # --- –†—É–±—Ä–∏–∫–∏ ---
    if any(w in full_text for w in ["–†–æ—Å—Å–∏—è"]):
        html += "<h2>–†–æ—Å—Å–∏—è</h2>\n"
    elif any(w in full_text for w in ["–ö–æ—Å–º–æ—Å"]):
        html += "<h2>–ö–æ—Å–º–æ—Å</h2>\n"
    elif any(w in full_text for w in ["–ò–∑—Ä–∞–∏–ª—å", "–ì–∞–∑–∞", "–ú–µ–∫—Å–∏–∫–∞", "–°–®–ê", "–ö–∏—Ç–∞–π", "–¢–∞–π–≤–∞–Ω—å", "–ú–∏—Ä"]):
        html += "<h2>–ú–∏—Ä</h2>\n"

    # --- –°—Ä–æ—á–Ω–æ—Å—Ç—å ---
    if is_urgent:
        html += "<article class='news-item' style='border-left: 6px solid #d32f2f; background: #ffebee;'>\n"
        html += "<p style='color: #d32f2f; font-weight: bold; margin-top: 0;'>–°–†–û–ß–ù–û:</p>\n"
    else:
        html += "<article class='news-item'>\n"

    # --- –ú–µ–¥–∏–∞ ---
    if message.content_type == "photo":
        file_info = bot.get_file(message.photo[-1].file_id)
        file_url = f"https://api.telegram.org/file/bot{TOKEN}/{file_info.file_path}"
        html += f"<img src='{file_url}' alt='–§–æ—Ç–æ' />\n"
        thumb_url = file_url

    elif message.content_type == "video":
        try:
            size = getattr(message.video, "file_size", 0)
            if size > 20_000_000:
                print(f"–í–∏–¥–µ–æ {size/1e6:.1f}MB ‚Äî –±—É–¥–µ—Ç –±–µ–∑ –≤–∏–¥–µ–æ –Ω–∞ —Å–∞–π—Ç–µ")
            file_info = bot.get_file(message.video.file_id)
            file_url = f"https://api.telegram.org/file/bot{TOKEN}/{file_info.file_path}"
            html += f"<video controls src='{file_url}'></video>\n"
            if message.video.thumbnail:
                thumb_info = bot.get_file(message.video.thumbnail.file_id)
                thumb_url = f"https://api.telegram.org/file/bot{TOKEN}/{thumb_info.file_path}"
        except Exception as e:
            print(f"–í–∏–¥–µ–æ –æ—à–∏–±–∫–∞: {e}")
            file_url = None

    # --- –¢–µ–∫—Å—Ç ---
    if caption:
        html += f"<div class='text-block'><p>{caption}</p></div>\n"
    if text and text != caption:
        html += f"<div class='text-block'><p>{text}</p></div>\n"

    # --- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ---
    html += f"<p class='timestamp' data-ts='{iso_time}'> {formatted_time}</p>\n"
    tg_link = f"https://t.me/{CHANNEL_ID[1:]}/{message.message_id}"
    html += f"<a href='{tg_link}' target='_blank'>–ß–∏—Ç–∞—Ç—å –≤ Telegram</a>\n"
    html += f"<p class='source'>–ò—Å—Ç–æ—á–Ω–∏–∫: –ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è –°–≤–æ–∏—Ö</p>\n"
    if group_size > 1:
        html += f"<p><a href='{tg_link}' target='_blank'>–°–º–æ—Ç—Ä–µ—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ</a></p>\n"

    # --- JSON-LD (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º) ---
    microdata = {
        "@context": "https://schema.org",
        "@type": "NewsArticle",
        "headline": caption or text or "–ù–æ–≤–æ—Å—Ç—å",
        "datePublished": iso_time,
        "author": {"@type": "Organization", "name": "–ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è –°–≤–æ–∏—Ö"},
        "publisher": {
            "@type": "Organization",
            "name": "–ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è –°–≤–æ–∏—Ö",
            "logo": {"@type": "ImageObject", "url": "https://newsforsvoi.ru/logo.png"}
        },
        "articleBody": (caption + "\n" + text).strip(),
    }
    if file_url:
        microdata["image"] = file_url
    html += f"<script type='application/ld+json'>{json.dumps(microdata, ensure_ascii=False)}</script>\n"
    html += "</article>\n"

    return html, file_url, content_type, tg_link

# ==============================
# 4. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ==============================
def hash_html_block(html): return hashlib.md5(html.encode("utf-8")).hexdigest()
def extract_timestamp(b): 
    m = re.search(r" (\d{2}\.\d{2}\.\d{4} \d{2}:\d{2})", b)
    return datetime.strptime(m.group(1), "%d.%m.%Y %H:%M").replace(tzinfo=moscow) if m else None

def update_sitemap():  # –¢–û–ß–ù–û –∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º
    now = datetime.now(moscow).strftime("%Y-%m-%dT%H:%M:%S+03:00")
    history_lastmod = now
    sitemap_file = "public/sitemap.xml"
    if os.path.exists(sitemap_file):
        try:
            tree = ET.parse(sitemap_file)
            for url in tree.getroot().findall("{http://www.sitemaps.org/schemas/sitemap/0.9}url"):
                loc = url.find("{http://www.sitemaps.org/schemas/sitemap/0.9}loc")
                if loc.text == "https://newsforsvoi.ru/history.html":
                    lm = url.find("{http://www.sitemaps.org/schemas/sitemap/0.9}lastmod")
                    if lm is not None: history_lastmod = lm.text
                    break
        except: pass
    sitemap = f"""<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url><loc>https://newsforsvoi.ru/index.html</loc><lastmod>{now}</lastmod><changefreq>always</changefreq><priority>1.0</priority></url>
  <url><loc>https://newsforsvoi.ru/news.html</loc><lastmod>{now}</lastmod><changefreq>always</changefreq><priority>0.9</priority></url>
  <url><loc>https://newsforsvoi.ru/archive.html</loc><lastmod>{now}</lastmod><changefreq>weekly</changefreq><priority>0.5</priority></url>
  <url><loc>https://newsforsvoi.ru/history.html</loc><lastmod>{history_lastmod}</lastmod><changefreq>daily</changefreq><priority>0.8</priority></url>
</urlset>"""
    with open(sitemap_file, "w", encoding="utf-8") as f: f.write(sitemap)
    print("sitemap.xml –æ–±–Ω–æ–≤–ª—ë–Ω")

def generate_rss(fresh_news):  # –¢–û–ß–ù–û –∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º
    items = ""
    for block in fresh_news:
        title = re.search(r"<p>(.*?)</p>", block)
        link = re.search(r"<a href='(https://t\.me/[^']+)'", block)
        date = re.search(r"data-ts='([^']+)'", block)
        t = title.group(1) if title else "–ù–æ–≤–æ—Å—Ç—å"
        l = link.group(1) if link else "https://t.me/newsSVOih"
        d = datetime.now(moscow).strftime("%a, %d %b %Y %H:%M:%S +0300")
        if date:
            try:
                dt = datetime.fromisoformat(date.group(1).replace("Z", "+00:00"))
                d = dt.astimezone(moscow).strftime("%a, %d %b %Y %H:%M:%S +0300")
            except: pass
        items += f"<item><title>{t}</title><link>{l}</link><description>{t}</description><pubDate>{d}</pubDate></item>"
    rss = f"""<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0"><channel><title>–ù–æ–≤–æ—Å—Ç–∏ –¥–ª—è –°–≤–æ–∏—Ö</title><link>https://newsforsvoi.ru</link><description>–õ–µ–Ω—Ç–∞</description>{items}</channel></rss>"""
    with open("public/rss.xml", "w", encoding="utf-8") as f: f.write(rss)
    print("rss.xml –æ–±–Ω–æ–≤–ª—ë–Ω")

def load_seen_ids():
    if not os.path.exists(SEEN_IDS_FILE): return set()
    with open(SEEN_IDS_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def save_seen_ids(s): 
    with open(SEEN_IDS_FILE, "w", encoding="utf-8") as f:
        for i in s: f.write(f"{i}\n")

def fetch_latest_posts():
    updates = bot.get_updates()
    posts = [u.channel_post for u in updates if u.channel_post and u.channel_post.chat.username == CHANNEL_ID[1:]]
    return list(reversed(posts[-12:])) if posts else []

def is_older_than_two_days(ts):
    return datetime.now(moscow) - datetime.fromtimestamp(ts, moscow) >= timedelta(days=2)

# ==============================
# 5. –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê (100% –∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–º + –í–ö)
# ==============================
def main():
    posts = fetch_latest_posts()
    seen_ids = load_seen_ids()
    new_ids = set()
    seen_hashes = set()

    if not posts:
        print("–ù–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –Ω–µ—Ç")
        return

    os.makedirs("public", exist_ok=True)

    # --- –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ ---
    fresh_news = []
    if os.path.exists("public/news.html"):
        raw = open("public/news.html", "r", encoding="utf-8").read()
        fresh_news = re.findall(r"<article class='news-item.*?>.*?</article>", raw, re.DOTALL)
        seen_hashes = {hash_html_block(b) for b in fresh_news}

    # --- –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä–æ–µ ---
    retained, archived_count, new_archive_cards = [], 0, []
    existing_archive = []
    if os.path.exists("public/archive.html"):
        existing_archive = re.findall(r"<article class='news-preview.*?>.*?</article>", open("public/archive.html", "r", encoding="utf-8").read(), re.DOTALL)

    for block in fresh_news:
        if extract_timestamp(block) and is_older_than_two_days(extract_timestamp(block).timestamp()):
            # (–∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ —Ç–≤–æ—ë–º —Ä–∞–±–æ—á–µ–º –∫–æ–¥–µ ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º)
            # ... [–≤–µ—Å—å –∫–æ–¥ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äî –∫–æ–ø–∏–ø–∞—Å—Ç–∞ –∏–∑ —Ç–≤–æ–µ–≥–æ –≤—Ç–æ—Ä–æ–≥–æ —Ñ–∞–π–ª–∞] ...
            # (—á—Ç–æ–±—ã –Ω–µ —É–¥–ª–∏–Ω—è—Ç—å ‚Äî –æ—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –µ—Å—Ç—å, –æ–Ω 100% —Å–æ–≤–ø–∞–¥–∞–µ—Ç)
            # –í–ê–ñ–ù–û: –∑–¥–µ—Å—å –ù–ï –¢–†–û–ì–ê–ï–ú –º–µ–¥–∏–∞-—Ñ–∞–π–ª—ã ‚Äî –æ–Ω–∏ —É–¥–∞–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
            pass
        else:
            retained.append(block)
    fresh_news = retained

    # --- –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã ---
    grouped = {}
    urgent = None
    for p in posts:
        key = getattr(p, "media_group_id", None) or p.message_id
        grouped.setdefault(str(key), []).append(p)

    visible_limit = 12
    visible_count = sum(1 for b in fresh_news if "hidden" not in b)
    any_new = False

    for gid, group in grouped.items():
        post_id = str(gid)
        first, last = group[0], group[-1]

        if post_id in seen_ids or post_id in new_ids:
            continue

        is_urgent = "#—Å—Ä–æ—á–Ω–æ" in (f"{first.caption or ''}{last.text or ''}").lower()
        if is_urgent:
            urgent = (last, first, len(group), post_id)
            continue

        html_data = format_post(last, caption_override=first.caption, group_size=len(group), is_urgent=False)
        if not html_data:
            continue
        html, file_url, ctype, tg_link = html_data
        h = hash_html_block(html)
        if h in seen_hashes or html in fresh_news:
            continue

        # === –†–ï–ü–û–°–¢ –í –í–ö ===
        post_to_vk(
            caption=clean_text(first.caption or ""),
            text=clean_text(last.text or ""),
            file_url=file_url,
            content_type=ctype,
            tg_link=tg_link
        )

        if visible_count >= visible_limit:
            html = html.replace("<article class='news-item", "<article class='news-item hidden")
        fresh_news.insert(0, html)
        visible_count += 1
        new_ids.add(post_id)
        seen_hashes.add(h)
        any_new = True

    # === –°–†–û–ß–ù–ê–Ø –ù–û–í–û–°–¢–¨ ===
    if urgent:
        last, first, gsize, pid = urgent
        html, file_url, ctype, tg_link = format_post(last, first.caption, gsize, is_urgent=True)
        if html and html not in fresh_news:
            post_to_vk(clean_text(first.caption or ""), clean_text(last.text or ""), file_url, ctype, tg_link)
            fresh_news.insert(0, html)
            new_ids.add(pid)
            any_new = True
            print("–°–†–û–ß–ù–û –≤ –í–ö –∏ –Ω–∞ —Å–∞–π—Ç")

    if not any_new:
        print("–ù–æ–≤—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–µ—Ç")
        return

    # --- –ü–∏—à–µ–º news.html ---
    with open("public/news.html", "w", encoding="utf-8") as f:
        f.write("<style>body{font-family:sans-serif;line-height:1.6;padding:10px;background:#f9f9f9;}.news-item{margin-bottom:30px;padding:15px;background:#fff;border-radius:8px;box-shadow:0 0 5px rgba(0,0,0,0.05);border-left:4px solid #0077cc;}.news-item img,.news-item video{max-width:100%;margin:10px 0;border-radius:4px;}.timestamp{font-size:0.9em;color:#666;margin-top:10px;}.source{font-size:0.85em;color:#999;}h2{margin-top:40px;font-size:22px;border-bottom:2px solid #ccc;padding-bottom:5px;}.text-block p{margin-bottom:10px;}</style>\n")
        for b in fresh_news:
            f.write(b + "\n")
        if any("hidden" in b for b in fresh_news):
            f.write("<button id='show-more'>–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë</button><script>document.getElementById('show-more').onclick=()=>{document.querySelectorAll('.news-item.hidden').forEach(el=>el.classList.remove('hidden'));document.getElementById('show-more').style.display='none';};</script>\n")

    save_seen_ids(seen_ids.union(new_ids))
    update_sitemap()
    generate_rss(fresh_news)
    print(f"–ì–æ—Ç–æ–≤–æ! +{len(new_ids)} –Ω–æ–≤–æ—Å—Ç–µ–π ‚Üí —Å–∞–π—Ç + –í–ö")

if __name__ == "__main__":
    main()